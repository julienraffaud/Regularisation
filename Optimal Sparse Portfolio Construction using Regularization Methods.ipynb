{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of assets\n",
    "dim = 48\n",
    "# length of rolling in-sample window in days\n",
    "tau = 250\n",
    "# length of out-of-sample window in days\n",
    "out = 21\n",
    "# VaR threshold\n",
    "var_thresh = 95\n",
    "# number of cross-validation folds\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Suppress annoying warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import + format dataset\n",
    "path = '/Users/julienraffaud/Desktop/Machine Learning with Applications in Finance/48_Industry_Portfolios_daily.CSV'\n",
    "data = pd.read_csv(path)\n",
    "data[data.columns[0]] = pd.to_datetime(data[data.columns[0]].astype(str), errors='coerce')\n",
    "data = data.rename(columns={ data.columns[0]: \"Date\" })\n",
    "data = data.set_index('Date')\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "data = data.iloc[-1401:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Minimum variance portfolio backtest\n",
    "mvp_returns = []\n",
    "for i in range(0, int((len(data) - tau)/out)):\n",
    "    # current window\n",
    "    window = np.array( data.iloc[i*out:i*out + tau, :] )\n",
    "    # Estimated covariance matrix\n",
    "    est_cov = np.cov(window.T)\n",
    "    # Inverse of estimated covariance matrix\n",
    "    cov_inv = np.linalg.inv( est_cov )\n",
    "    # dim*1 vector of ones\n",
    "    ones = np.ones((dim, 1))\n",
    "    # First half of mvp weights formula\n",
    "    a = np.linalg.inv( np.linalg.multi_dot(( ones.T, cov_inv, ones)) )\n",
    "    # Second half of mvp weights formula\n",
    "    b = np.dot( cov_inv, ones)\n",
    "    # Minimum Variance Portfolio weights\n",
    "    mvp = a*b\n",
    "    # In-sample variance of the MVP\n",
    "    var_in = np.linalg.multi_dot((mvp.T, est_cov, mvp))\n",
    "    # out-of-sample data\n",
    "    out_sample = np.array( data.iloc[i*out+tau:i*out+tau+out, :].T )\n",
    "    # out-of-sample returns\n",
    "    out_returns = np.dot(mvp.T, out_sample)\n",
    "    mvp_returns += out_returns.T.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of out-of-sample returns measured\n",
    "nob = int((len(data) - tau)/out)*out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5745083094795582\n",
      "-0.8546721538677073\n",
      "0.15201022882228912\n"
     ]
    }
   ],
   "source": [
    "# compute MVP variance\n",
    "mvp_variance = np.var(mvp_returns)\n",
    "# compute MVP VaR at (1-var_thresh)% level\n",
    "mvp_var = np.percentile(mvp_returns, 100-var_thresh)\n",
    "# compute MVP Sharpe ratio\n",
    "mvp_sharpe = np.mean( mvp_returns )/np.sqrt(mvp_variance)\n",
    "print(np.sqrt(mvp_variance))\n",
    "print(mvp_var)\n",
    "print(mvp_sharpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1254,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## RIDGE-regularized portfolio backtest\n",
    "# lambdas\n",
    "lmbd = np.linspace(0, 1, 100)\n",
    "ridge_returns = []\n",
    "for i in range(0, int((len(data) - tau)/out)):\n",
    "    # current window\n",
    "    window = np.array( data.iloc[i*out:i*out + tau, :] )\n",
    "    # average out-of-sample variance associated with each lambda\n",
    "    lmbd_variances = np.zeros((len(lmbd), 1))\n",
    "    for fold in range(0, k):\n",
    "        variances = []\n",
    "        # sample values from in-sample data\n",
    "        sample = np.random.choice(tau, out, replace=False)\n",
    "        # remaining in-sample data\n",
    "        mod_window = np.delete(window, sample, axis=0)\n",
    "        # out-of-sample data\n",
    "        outer = window[sample, :]\n",
    "        # dim*1 vector of ones\n",
    "        ones = np.ones((dim, 1))\n",
    "        # Estimated covariance matrix\n",
    "        est_cov = np.cov(mod_window.T)\n",
    "        ## CROSS-VALIDATION STEP\n",
    "        for l in lmbd:\n",
    "            cov_inv = np.linalg.inv( est_cov+l*np.eye(dim) )\n",
    "            # First half of mvp weights formula\n",
    "            a = np.linalg.inv( np.linalg.multi_dot(( ones.T, cov_inv, ones)) )\n",
    "            # Second half of mvp weights formula\n",
    "            b = np.dot( cov_inv, ones)\n",
    "            # Portfolio weights\n",
    "            mvp = a*b\n",
    "            # In-sample variance of the MVP\n",
    "            var_in = np.linalg.multi_dot((mvp.T, est_cov, mvp))\n",
    "            # out-of-sample variance associated to each lambda\n",
    "            var_out = np.var(np.dot(mvp.T, outer.T).T )\n",
    "            # append variance\n",
    "            variances.append( var_out )\n",
    "        variances = np.array(variances)\n",
    "        variances.shape = (len(lmbd), 1)\n",
    "        # update each lambda's corresponding variance\n",
    "        lmbd_variances += variances/k\n",
    "    # index of lambda*\n",
    "    star = lmbd_variances.tolist().index(min(lmbd_variances)) \n",
    "    # lambda*\n",
    "    lambda_star = lmbd[lmbd_variances.tolist().index(min(lmbd_variances))]\n",
    "    ## END OF CROSS VALIDATION STEP\n",
    "    # estimated covariance matrix\n",
    "    est_cov = np.cov(window.T)\n",
    "    # inverted covariance matrix\n",
    "    cov_inv = np.linalg.inv( est_cov + lambda_star*np.eye(dim))\n",
    "    a = np.linalg.inv( np.linalg.multi_dot(( ones.T, cov_inv, ones)) )\n",
    "    # Second half of mvp weights formula\n",
    "    b = np.dot( cov_inv, ones)\n",
    "    # Portfolio weights\n",
    "    mvp = a*b\n",
    "    # out-of-sample data\n",
    "    out_sample = np.array( data.iloc[i*out+tau:i*out+tau+out, :].T )\n",
    "    # out-of-sample returns\n",
    "    out_returns = np.dot(mvp.T, out_sample)\n",
    "    ridge_returns += out_returns.T.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5621236882440815\n",
      "-0.8550044096349942\n",
      "0.15322037096935828\n"
     ]
    }
   ],
   "source": [
    "# compute ridge portfolio variance\n",
    "ridge_variance = np.var(ridge_returns)\n",
    "# compute RP VaR at (1-var_thresh)% level\n",
    "ridge_var = np.percentile(ridge_returns, 100-var_thresh)\n",
    "# compute RP Sharpe ratio\n",
    "ridge_sharpe = np.mean( ridge_returns )/np.sqrt(ridge_variance)\n",
    "print(np.sqrt(ridge_variance))\n",
    "print(ridge_var)\n",
    "print(ridge_sharpe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
