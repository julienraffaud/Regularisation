{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "# Suppress annoying warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import + format dataset\n",
    "path = '/Users/julienraffaud/Desktop/Machine Learning with Applications in Finance/48_Industry_Portfolios_daily.CSV'\n",
    "data = pd.read_csv(path)\n",
    "data[data.columns[0]] = pd.to_datetime(data[data.columns[0]].astype(str), errors='coerce')\n",
    "data = data.rename(columns={ data.columns[0]: \"Date\" })\n",
    "data = data.set_index('Date')\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "data = data.iloc[-1500:, :]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of assets\n",
    "dim = 48\n",
    "# sample size (250=1year, 125=6months, 63=3months)\n",
    "tau = 205\n",
    "# length of out-of-sample window in days\n",
    "out = 80\n",
    "# VaR threshold\n",
    "var_thresh = 95\n",
    "# number of cross-validation folds\n",
    "k = 10\n",
    "# number of lambda to test @ each fold\n",
    "grid = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regulariser penalty functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MVP(x, cov):\n",
    "    return np.linalg.multi_dot((x, cov, x.T))\n",
    "\n",
    "def LASSO(x, cov, lmbd):\n",
    "    return 10**4*(np.linalg.multi_dot((x, cov, x.T)) + lmbd*np.sum(abs(x)))\n",
    "\n",
    "def RIDGE(x, cov, lmbd):\n",
    "    return 10**4*(np.linalg.multi_dot((x, cov, x.T)) + lmbd*np.sum(abs(x)**2))\n",
    "\n",
    "def W8LASS(x, cov, lmbd):\n",
    "    gamma = 0.5\n",
    "    indiv_weights = 1/(abs(x)**gamma)\n",
    "    return 10**4*(np.linalg.multi_dot((x, cov, x.T)) + np.sum(np.dot(lmbd*indiv_weights, abs(x.T))))\n",
    "\n",
    "def SCAD(x, cov, lmbd):\n",
    "    a = 3.7\n",
    "    variance = np.linalg.multi_dot((x, cov, x.T))\n",
    "    x_mod = np.copy(x)\n",
    "    x_mod[abs(x_mod)<=lmbd] = lmbd*abs(x_mod[abs(x_mod)<=lmbd])\n",
    "    x_mod[abs(x_mod)>lmbd*a] = ((a+1)*lmbd**2)/2\n",
    "    x_mod[(abs(x_mod) > lmbd ) & (abs(x_mod) <= a*lmbd)] = (-abs(x_mod[(abs(x_mod) > lmbd ) & (abs(x_mod) <= a*lmbd)])**2 + 2*a*lmbd*abs(x_mod[(abs(x_mod) > lmbd ) & (abs(x_mod) <= a*lmbd)]) - lmbd**2 )/(2*(a-1))\n",
    "    return 10**4*(variance + np.sum(x_mod))\n",
    "\n",
    "def Zhang(x, cov, lmbd):\n",
    "    variance =  np.linalg.multi_dot((x, cov, x.T))\n",
    "    eps = 0.005\n",
    "    x_mod = np.copy(x)\n",
    "    x_mod[abs(x_mod)>=eps] = eps\n",
    "    reg = lmbd*np.sum(abs(x))\n",
    "    return 10**4*(variance + reg)\n",
    "\n",
    "def Lq(x, cov, lmbd):\n",
    "    return 10**4*(np.linalg.multi_dot((x, cov, x.T)) + lmbd*np.sum(abs(x)**0.5))\n",
    "\n",
    "def Log(x, cov, lmbd):\n",
    "    psi = 0.01\n",
    "    return 10**4*(np.linalg.multi_dot((x, cov, x.T)) + lmbd*np.sum(np.log((abs(x)+psi)/(psi))))\n",
    "\n",
    "# defining linear constraint\n",
    "cons = {'type':'eq', 'fun': lambda x: np.sum(x) - 1}\n",
    "\n",
    "#define starting weights\n",
    "x0 = np.ones((1, dim))*(1/dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equally-weighted invariant portfolio (benchmark):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equal-weights portfolio backtest (benchmark)\n",
    "bench_returns = []\n",
    "for i in range(0, int((len(data) - tau)/out)):\n",
    "    # current window\n",
    "    window = np.array( data.iloc[i*out:i*out + tau, :] )\n",
    "    # equal weights\n",
    "    mv_equal = (1/dim)*np.ones((1, dim)).T\n",
    "    # out-of-sample data\n",
    "    out_sample = np.array( data.iloc[i*out+tau:i*out+tau+out, :].T )\n",
    "    # out-of-sample returns\n",
    "    out_returns = np.dot(mv_equal.T, out_sample)\n",
    "    bench_returns += out_returns.T.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.53184639642265e-05\n",
      "-0.01435875\n",
      "0.06616718291145465\n"
     ]
    }
   ],
   "source": [
    "# compute return variance\n",
    "equal_variance = np.var(bench_returns)\n",
    "# compute VaR at (1-var_thresh)% level\n",
    "equal_var = np.percentile(bench_returns, 100-var_thresh)\n",
    "# compute Sharpe ratio\n",
    "equal_sharpe = np.mean( bench_returns )/np.sqrt(equal_variance)\n",
    "print(equal_variance)\n",
    "print(equal_var)\n",
    "print(equal_sharpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum Variance Portfolio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum variance portfolio backtest\n",
    "mvp_returns = []\n",
    "for i in range(0, int((len(data) - tau)/out)):\n",
    "    # current window\n",
    "    window = np.array( data.iloc[i*out:i*out + tau, :] )\n",
    "    # Estimated covariance matrix\n",
    "    est_cov = np.cov(window.T)\n",
    "    # Inverse of estimated covariance matrix\n",
    "    cov_inv = np.linalg.inv( est_cov )\n",
    "    # dim*1 vector of ones\n",
    "    ones = np.ones((dim, 1))\n",
    "    # First half of mvp weights formula\n",
    "    a = np.linalg.inv( np.linalg.multi_dot(( ones.T, cov_inv, ones)) )\n",
    "    # Second half of mvp weights formula\n",
    "    b = np.dot( cov_inv, ones)\n",
    "    # Minimum Variance Portfolio weights\n",
    "    mvp = a*b\n",
    "    # In-sample variance of the MVP\n",
    "    var_in = np.linalg.multi_dot((mvp.T, est_cov, mvp))\n",
    "    # out-of-sample data\n",
    "    out_sample = np.array( data.iloc[i*out+tau:i*out+tau+out, :].T )\n",
    "    # out-of-sample returns\n",
    "    out_returns = np.dot(mvp.T, out_sample)\n",
    "    mvp_returns += out_returns.T.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.50194189340695e-05\n",
      "-0.008965540384127037\n",
      "0.15278747559358033\n"
     ]
    }
   ],
   "source": [
    "# compute MVP variance\n",
    "mvp_variance = np.var(mvp_returns)\n",
    "# compute MVP VaR at (1-var_thresh)% level\n",
    "mvp_var = np.percentile(mvp_returns, 100-var_thresh)\n",
    "# compute MVP Sharpe ratio\n",
    "mvp_sharpe = np.mean( mvp_returns )/np.sqrt(mvp_variance)\n",
    "print(mvp_variance)\n",
    "print(mvp_var)\n",
    "print(mvp_sharpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LASSO-regularised portfolio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# LASSO-regularised portfolio backtest\n",
    "# lambdas\n",
    "lmbd = np.linspace(0, 3.*10**(-5), grid)\n",
    "LASSO_returns = []\n",
    "for i in range(0, int((len(data) - tau)/out)):\n",
    "    print(i)\n",
    "    # current window\n",
    "    window = np.array( data.iloc[i*out:i*out + tau, :] )\n",
    "    # average out-of-sample variance associated with each lambda\n",
    "    lmbd_variances = np.zeros((len(lmbd), 1))\n",
    "    for fold in range(0, k):\n",
    "        variances = []\n",
    "        # sample values from in-sample data\n",
    "        sample = np.random.choice(tau, out, replace=False)\n",
    "        # remaining in-sample data\n",
    "        mod_window = np.delete(window, sample, axis=0)\n",
    "        # out-of-sample data\n",
    "        outer = window[sample, :]\n",
    "        # Estimated covariance matrix\n",
    "        est_cov = np.cov(mod_window.T)\n",
    "        ## CROSS-VALIDATION STEP\n",
    "        for l in lmbd:\n",
    "            # Portfolio weights\n",
    "            mvp = minimize(LASSO, x0, (est_cov, l), constraints=cons).x\n",
    "            # out-of-sample variance associated to each lambda\n",
    "            var_out = np.var(np.dot(mvp.T, outer.T).T )\n",
    "            # append variance\n",
    "            variances.append( var_out )\n",
    "        variances = np.array(variances)\n",
    "        variances.shape = (len(lmbd), 1)\n",
    "        # update each lambda's corresponding variance\n",
    "        lmbd_variances += variances/k\n",
    "    # index of lambda*\n",
    "    star = lmbd_variances.tolist().index(min(lmbd_variances)) \n",
    "    # lambda*\n",
    "    lambda_star = lmbd[lmbd_variances.tolist().index(min(lmbd_variances))]\n",
    "    ## END OF CROSS VALIDATION STEP\n",
    "    # estimated covariance matrix\n",
    "    est_cov = np.cov(window.T)\n",
    "    # Portfolio weights\n",
    "    mvp = minimize(LASSO, x0, (est_cov, lambda_star), constraints=cons).x\n",
    "    # out-of-sample data\n",
    "    out_sample = np.array( data.iloc[i*out+tau:i*out+tau+out, :].T )\n",
    "    # out-of-sample returns\n",
    "    out_returns = np.dot(mvp.T, out_sample)\n",
    "    LASSO_returns += out_returns.T.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.284804329020193e-05\n",
      "-0.008835405975458628\n",
      "0.15662634425584376\n"
     ]
    }
   ],
   "source": [
    "# compute LASSO variance\n",
    "LASSO_variance = np.var(LASSO_returns)\n",
    "# compute LASSO VaR at (1-var_thresh)% level\n",
    "LASSO_var = np.percentile(LASSO_returns, 100-var_thresh)\n",
    "# compute LASSO Sharpe ratio\n",
    "LASSO_sharpe = np.mean( LASSO_returns )/np.sqrt(LASSO_variance)\n",
    "print(LASSO_variance)\n",
    "print(LASSO_var)\n",
    "print(LASSO_sharpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge-regularised portfolio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# RIDGE-regularised portfolio backtest\n",
    "# lambdas\n",
    "lmbd = np.linspace(0, 13.5*10**(-5), grid)\n",
    "RIDGE_returns = []\n",
    "for i in range(0, int((len(data) - tau)/out)):\n",
    "    print(i)\n",
    "    # current window\n",
    "    window = np.array( data.iloc[i*out:i*out + tau, :] )\n",
    "    # average out-of-sample variance associated with each lambda\n",
    "    lmbd_variances = np.zeros((len(lmbd), 1))\n",
    "    for fold in range(0, k):\n",
    "        variances = []\n",
    "        # sample values from in-sample data\n",
    "        sample = np.random.choice(tau, out, replace=False)\n",
    "        # remaining in-sample data\n",
    "        mod_window = np.delete(window, sample, axis=0)\n",
    "        # out-of-sample data\n",
    "        outer = window[sample, :]\n",
    "        # Estimated covariance matrix\n",
    "        est_cov = np.cov(mod_window.T)\n",
    "        ## CROSS-VALIDATION STEP\n",
    "        for l in lmbd:\n",
    "            # Portfolio weights\n",
    "            mvp = minimize(RIDGE, x0, (est_cov, l), constraints=cons).x\n",
    "            # out-of-sample variance associated to each lambda\n",
    "            var_out = np.var(np.dot(mvp.T, outer.T).T )\n",
    "            # append variance\n",
    "            variances.append( var_out )\n",
    "        variances = np.array(variances)\n",
    "        variances.shape = (len(lmbd), 1)\n",
    "        # update each lambda's corresponding variance\n",
    "        lmbd_variances += variances/k\n",
    "    # index of lambda*\n",
    "    star = lmbd_variances.tolist().index(min(lmbd_variances)) \n",
    "    # lambda*\n",
    "    lambda_star = lmbd[lmbd_variances.tolist().index(min(lmbd_variances))]\n",
    "    ## END OF CROSS VALIDATION STEP\n",
    "    # estimated covariance matrix\n",
    "    est_cov = np.cov(window.T)\n",
    "    # Portfolio weights\n",
    "    mvp = minimize(RIDGE, x0, (est_cov, lambda_star), constraints=cons).x\n",
    "    # out-of-sample data\n",
    "    out_sample = np.array( data.iloc[i*out+tau:i*out+tau+out, :].T )\n",
    "    # out-of-sample returns\n",
    "    out_returns = np.dot(mvp.T, out_sample)\n",
    "    RIDGE_returns += out_returns.T.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.240363128621679e-05\n",
      "-0.008984323242248855\n",
      "0.14491071562211344\n"
     ]
    }
   ],
   "source": [
    "# compute Ridge variance\n",
    "RIDGE_variance = np.var(RIDGE_returns)\n",
    "# Compute Ridge VaR at (1-var_thresh)% level\n",
    "RIDGE_var = np.percentile(RIDGE_returns, 100-var_thresh)\n",
    "# compute Ridge Sharpe ratio\n",
    "RIDGE_sharpe = np.mean( RIDGE_returns )/np.sqrt(RIDGE_variance)\n",
    "print(RIDGE_variance)\n",
    "print(RIDGE_var)\n",
    "print(RIDGE_sharpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted Lasso (w8LASS) portfolio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# w8LASS-regularised portfolio backtest\n",
    "# lambdas\n",
    "lmbd = np.linspace(0, 7.5*10**(-6), grid)\n",
    "W8_returns = []\n",
    "for i in range(0, int((len(data) - tau)/out)):\n",
    "    print(i)\n",
    "    # current window\n",
    "    window = np.array( data.iloc[i*out:i*out + tau, :] )\n",
    "    # average out-of-sample variance associated with each lambda\n",
    "    lmbd_variances = np.zeros((len(lmbd), 1))\n",
    "    for fold in range(0, k):\n",
    "        variances = []\n",
    "        # sample values from in-sample data\n",
    "        sample = np.random.choice(tau, out, replace=False)\n",
    "        # remaining in-sample data\n",
    "        mod_window = np.delete(window, sample, axis=0)\n",
    "        # out-of-sample data\n",
    "        outer = window[sample, :]\n",
    "        # Estimated covariance matrix\n",
    "        est_cov = np.cov(mod_window.T)\n",
    "        ## CROSS-VALIDATION STEP\n",
    "        for l in lmbd:\n",
    "            # Portfolio weights\n",
    "            mvp = minimize(W8LASS, x0, (est_cov, l), constraints=cons, tol=10**(-4)).x\n",
    "            # out-of-sample variance associated to each lambda\n",
    "            var_out = np.var(np.dot(mvp.T, outer.T).T )\n",
    "            # append variance\n",
    "            variances.append( var_out )\n",
    "        variances = np.array(variances)\n",
    "        variances.shape = (len(lmbd), 1)\n",
    "        # update each lambda's corresponding variance\n",
    "        lmbd_variances += variances/k\n",
    "    # index of lambda*\n",
    "    star = lmbd_variances.tolist().index(min(lmbd_variances)) \n",
    "    # lambda*\n",
    "    lambda_star = lmbd[lmbd_variances.tolist().index(min(lmbd_variances))]\n",
    "    ## END OF CROSS VALIDATION STEP\n",
    "    # estimated covariance matrix\n",
    "    est_cov = np.cov(window.T)\n",
    "    # Portfolio weights\n",
    "    mvp = minimize(W8LASS, x0, (est_cov, lambda_star), constraints=cons).x\n",
    "    # out-of-sample data\n",
    "    out_sample = np.array( data.iloc[i*out+tau:i*out+tau+out, :].T )\n",
    "    # out-of-sample returns\n",
    "    out_returns = np.dot(mvp.T, out_sample)\n",
    "    W8_returns += out_returns.T.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6828938416035383e-05\n",
      "-0.009216850443639393\n",
      "0.14620402944929478\n"
     ]
    }
   ],
   "source": [
    "# compute W8 variance\n",
    "W8_variance = np.var(W8_returns)\n",
    "# compute W8 VaR at (1-var_thresh)% level\n",
    "W8_var = np.percentile(W8_returns, 100-var_thresh)\n",
    "# compute W8 Sharpe ratio\n",
    "W8_sharpe = np.mean( W8_returns )/np.sqrt(W8_variance)\n",
    "print(W8_variance)\n",
    "print(W8_var)\n",
    "print(W8_sharpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCAD-regularised portfolio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# SCAD-regularised portfolio backtest\n",
    "# lambdas\n",
    "lmbd = np.linspace(0, 17*10**(-3.4), grid)\n",
    "scad_returns = []\n",
    "for i in range(0, int((len(data) - tau)/out)):\n",
    "    print(i)\n",
    "    # current window\n",
    "    window = np.array( data.iloc[i*out:i*out + tau, :] )\n",
    "    # average out-of-sample variance associated with each lambda\n",
    "    lmbd_variances = np.zeros((len(lmbd), 1))\n",
    "    for fold in range(0, k):\n",
    "        variances = []\n",
    "        # sample values from in-sample data\n",
    "        sample = np.random.choice(tau, out, replace=False)\n",
    "        # remaining in-sample data\n",
    "        mod_window = np.delete(window, sample, axis=0)\n",
    "        # out-of-sample data\n",
    "        outer = window[sample, :]\n",
    "        # Estimated covariance matrix\n",
    "        est_cov = np.cov(mod_window.T)\n",
    "        ## CROSS-VALIDATION STEP\n",
    "        for l in lmbd:\n",
    "            # Portfolio weights\n",
    "            mvp = minimize(SCAD, x0, (est_cov, l), constraints=cons, tol=10**(-4)).x\n",
    "            # out-of-sample variance associated to each lambda\n",
    "            var_out = np.var(np.dot(mvp.T, outer.T).T )\n",
    "            # append variance\n",
    "            variances.append( var_out )\n",
    "        variances = np.array(variances)\n",
    "        variances.shape = (len(lmbd), 1)\n",
    "        # update each lambda's corresponding variance\n",
    "        lmbd_variances += variances/k\n",
    "    # index of lambda*\n",
    "    star = lmbd_variances.tolist().index(min(lmbd_variances)) \n",
    "    # lambda*\n",
    "    lambda_star = lmbd[lmbd_variances.tolist().index(min(lmbd_variances))]\n",
    "    ## END OF CROSS VALIDATION STEP\n",
    "    # estimated covariance matrix\n",
    "    est_cov = np.cov(window.T)\n",
    "    # Portfolio weights\n",
    "    mvp = minimize(SCAD, x0, (est_cov, lambda_star), constraints=cons).x\n",
    "    # out-of-sample data\n",
    "    out_sample = np.array( data.iloc[i*out+tau:i*out+tau+out, :].T )\n",
    "    # out-of-sample returns\n",
    "    out_returns = np.dot(mvp.T, out_sample)\n",
    "    scad_returns += out_returns.T.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.457068964299519e-05\n",
      "-0.008797461469111577\n",
      "0.1467008668837796\n"
     ]
    }
   ],
   "source": [
    "# compute SCAD variance\n",
    "SCAD_variance = np.var(scad_returns)\n",
    "# compute SCAD VaR at (1-var_thresh)% level\n",
    "SCAD_var = np.percentile(scad_returns, 100-var_thresh)\n",
    "# compute SCAD Sharpe ratio\n",
    "SCAD_sharpe = np.mean( scad_returns )/np.sqrt(SCAD_variance)\n",
    "print(SCAD_variance)\n",
    "print(SCAD_var)\n",
    "print(SCAD_sharpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log-regularised portfolio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Log-regularised portfolio backtest\n",
    "# lambdas\n",
    "lmbd = np.linspace(0, 45*10**(-8), grid)\n",
    "log_returns = []\n",
    "for i in range(0, int((len(data) - tau)/out)):\n",
    "    print(i)\n",
    "    # current window\n",
    "    window = np.array( data.iloc[i*out:i*out + tau, :] )\n",
    "    # average out-of-sample variance associated with each lambda\n",
    "    lmbd_variances = np.zeros((len(lmbd), 1))\n",
    "    for fold in range(0, k):\n",
    "        variances = []\n",
    "        # sample values from in-sample data\n",
    "        sample = np.random.choice(tau, out, replace=False)\n",
    "        # remaining in-sample data\n",
    "        mod_window = np.delete(window, sample, axis=0)\n",
    "        # out-of-sample data\n",
    "        outer = window[sample, :]\n",
    "        # Estimated covariance matrix\n",
    "        est_cov = np.cov(mod_window.T)\n",
    "        ## CROSS-VALIDATION STEP\n",
    "        for l in lmbd:\n",
    "            # Portfolio weights\n",
    "            mvp = minimize(Log, x0, (est_cov, l), constraints=cons, tol=10**(-4)).x\n",
    "            # out-of-sample variance associated to each lambda\n",
    "            var_out = np.var(np.dot(mvp.T, outer.T).T )\n",
    "            # append variance\n",
    "            variances.append( var_out )\n",
    "        variances = np.array(variances)\n",
    "        variances.shape = (len(lmbd), 1)\n",
    "        # update each lambda's corresponding variance\n",
    "        lmbd_variances += variances/k\n",
    "    # index of lambda*\n",
    "    star = lmbd_variances.tolist().index(min(lmbd_variances)) \n",
    "    # lambda*\n",
    "    lambda_star = lmbd[lmbd_variances.tolist().index(min(lmbd_variances))]\n",
    "    ## END OF CROSS VALIDATION STEP\n",
    "    # estimated covariance matrix\n",
    "    est_cov = np.cov(window.T)\n",
    "    # Portfolio weights\n",
    "    mvp = minimize(Log, x0, (est_cov, lambda_star), constraints=cons).x\n",
    "    # out-of-sample data\n",
    "    out_sample = np.array( data.iloc[i*out+tau:i*out+tau+out, :].T )\n",
    "    # out-of-sample returns\n",
    "    out_returns = np.dot(mvp.T, out_sample)\n",
    "    log_returns += out_returns.T.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.525748070382623e-05\n",
      "-0.008884578086235809\n",
      "0.1589493787023106\n"
     ]
    }
   ],
   "source": [
    "# compute log variance\n",
    "log_variance = np.var(log_returns)\n",
    "# compute log VaR at (1-var_thresh)% level\n",
    "log_var = np.percentile(log_returns, 100-var_thresh)\n",
    "# compute log Sharpe ratio\n",
    "log_sharpe = np.mean( log_returns )/np.sqrt(log_variance)\n",
    "print(log_variance)\n",
    "print(log_var)\n",
    "print(log_sharpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lq-regularised portfolio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Lq-regularised portfolio backtest\n",
    "# lambdas\n",
    "lmbd = np.linspace(0, 48*10**(-7), grid)\n",
    "lq_returns = []\n",
    "for i in range(0, int((len(data) - tau)/out)):\n",
    "    print(i)\n",
    "    # current window\n",
    "    window = np.array( data.iloc[i*out:i*out + tau, :] )\n",
    "    # average out-of-sample variance associated with each lambda\n",
    "    lmbd_variances = np.zeros((len(lmbd), 1))\n",
    "    for fold in range(0, k):\n",
    "        variances = []\n",
    "        # sample values from in-sample data\n",
    "        sample = np.random.choice(tau, out, replace=False)\n",
    "        # remaining in-sample data\n",
    "        mod_window = np.delete(window, sample, axis=0)\n",
    "        # out-of-sample data\n",
    "        outer = window[sample, :]\n",
    "        # Estimated covariance matrix\n",
    "        est_cov = np.cov(mod_window.T)\n",
    "        ## CROSS-VALIDATION STEP\n",
    "        for l in lmbd:\n",
    "            # Portfolio weights\n",
    "            mvp = minimize(Lq, x0, (est_cov, l), constraints=cons, tol=10**(-4)).x\n",
    "            # out-of-sample variance associated to each lambda\n",
    "            var_out = np.var(np.dot(mvp.T, outer.T).T )\n",
    "            # append variance\n",
    "            variances.append( var_out )\n",
    "        variances = np.array(variances)\n",
    "        variances.shape = (len(lmbd), 1)\n",
    "        # update each lambda's corresponding variance\n",
    "        lmbd_variances += variances/k\n",
    "    # index of lambda*\n",
    "    star = lmbd_variances.tolist().index(min(lmbd_variances)) \n",
    "    # lambda*\n",
    "    lambda_star = lmbd[lmbd_variances.tolist().index(min(lmbd_variances))]\n",
    "    ## END OF CROSS VALIDATION STEP\n",
    "    # estimated covariance matrix\n",
    "    est_cov = np.cov(window.T)\n",
    "    # Portfolio weights\n",
    "    mvp = minimize(Lq, x0, (est_cov, lambda_star), constraints=cons).x\n",
    "    # out-of-sample data\n",
    "    out_sample = np.array( data.iloc[i*out+tau:i*out+tau+out, :].T )\n",
    "    # out-of-sample returns\n",
    "    out_returns = np.dot(mvp.T, out_sample)\n",
    "    lq_returns += out_returns.T.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3816475904986015e-05\n",
      "-0.008780028134422914\n",
      "0.1583823620668408\n"
     ]
    }
   ],
   "source": [
    "# compute Lq variance\n",
    "lq_variance = np.var(lq_returns)\n",
    "# compute Lq VaR at (1-var_thresh)% level\n",
    "lq_var = np.percentile(lq_returns, 100-var_thresh)\n",
    "# compute Lq Sharpe ratio\n",
    "lq_sharpe = np.mean( lq_returns )/np.sqrt(lq_variance)\n",
    "print(lq_variance)\n",
    "print(lq_var)\n",
    "print(lq_sharpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "variances = [equal_variance, mvp_variance, LASSO_variance, RIDGE_variance, W8_variance, SCAD_variance, log_variance, lq_variance]\n",
    "v_risk = [equal_var, mvp_var, LASSO_var, RIDGE_var, W8_var, SCAD_var, log_var, lq_var]\n",
    "sharpes = [equal_sharpe, mvp_sharpe, LASSO_sharpe, RIDGE_sharpe, W8_sharpe, SCAD_sharpe, log_sharpe, lq_sharpe]\n",
    "penalties = ['Eq. weight','Unreg. MVP','LASSO', 'Ridge', '$w8LASS$', 'SCAD', 'Log', '$L_q$']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
